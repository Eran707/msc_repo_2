{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIGURE 4 - CURRENT FLOW INTO COMPARTMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All relevant classes imported\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "        \n",
    "    import h5py\n",
    "    \n",
    "    from ipywidgets import widgets, Layout, interact, interactive, interactive_output, Dropdown\n",
    "    from IPython.display import display\n",
    "    import matplotlib.pyplot as mplt\n",
    "    import numpy as np\n",
    "    import random\n",
    "    import seaborn as sns \n",
    "    import pandas as pd\n",
    "    import graphing as gr\n",
    "    #!pip install viola\n",
    "    ########## Modules required for artist drawing on matplotlib\n",
    "    import matplotlib.path as mpath\n",
    "    import matplotlib.lines as mlines\n",
    "    import matplotlib.patches as mpatches\n",
    "    from matplotlib.collections import PatchCollection\n",
    "    \n",
    "      \n",
    "except ModuleNotFoundError:\n",
    "        print(\"A class you are trying to import is not present in the directory\")\n",
    "    \n",
    "except Exception:\n",
    "        print(\"Something went wrong - modules have not been imported\")\n",
    "\n",
    "else: \n",
    "    print(\"All relevant classes imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELECT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df84a6841bc4aa79b34c53e2130bd8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Experiment-H1', description='File name')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc2411aef4f4a2a9fdec6ee4db030cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Select file', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcc086c0b5d4f02a0b21712484d57a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################\n",
    "#### GUI \n",
    "\n",
    "edt_filename = widgets.Text(description = 'File name', value='Experiment-H1')\n",
    "btn_select = widgets.Button(description = 'Select file',button_style='success')\n",
    "output_file = widgets.Output()\n",
    "\n",
    "display(edt_filename, btn_select,output_file)\n",
    "\n",
    "\n",
    "\n",
    "#######################################################\n",
    "#### FUNCTIONS\n",
    "\n",
    "\n",
    "#df_flux = pd.DataFrame({'Compartment':[],'Na_net':[], 'Na_leak':[],'Na_Atpase':[], 'K_net':[],'K_leak':[],'K_Atpase':[],'K_kcc2':[], 'Cl_net':[],'Cl_kcc2':[],'X':[],'z':[]  })\n",
    "df_ed = pd.DataFrame({'Boundary':[],'Na':[],'K':[],'Cl':[]})\n",
    "\n",
    "\n",
    "\n",
    "def btn_select_clicked(b):\n",
    "    global file_name, df_end, df_start, df_end_flux, df_end_ed, df_end_net_flux\n",
    "    file_name = \"\\\\\"\n",
    "    file_name = file_name + edt_filename.value \n",
    "    \n",
    "    try: \n",
    "        with h5py.File(file_name, mode='r') as hdf:\n",
    "            \n",
    "            print(\"File found and content loaded into memory\")\n",
    "            global C, comp_names_arr, intervals, interval_arr, master_arr, t_arr, ED_master_arr,E_group_arr\n",
    "            C = hdf.get('COMPARTMENTS')\n",
    "            C_group_arr =[]\n",
    "            t_arr_bool = True\n",
    "            comp_names_arr= list(C.keys())\n",
    "                        \n",
    "            C1 = C.get(comp_names_arr[0])\n",
    "            \n",
    "            T = hdf.get('TIMING')\n",
    "            total_t = T.get('TOTAL_T')[()]\n",
    "            intervals = T.get('INTERVALS')[()]\n",
    "            dt = T.get(\"DT\")[()]\n",
    "            total_steps = total_t /dt          \n",
    "            interval_step = total_steps / intervals\n",
    "            interval_arr = [round(interval_step * i) for i in range(intervals)]\n",
    "            \n",
    "            master_arr = []\n",
    "            t_arr =[]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ##### LOADING COMPARTMENT DATA\n",
    "            for e in range(len(comp_names_arr)):\n",
    "                C_group = C.get(comp_names_arr[e])\n",
    "                C_group_arr.append(C_group)\n",
    "               \n",
    "                data_arr_2 =[]\n",
    "                for j in range(len(list(C_group.keys()))):\n",
    "                    dataset = C_group.get(str(interval_arr[j]))\n",
    "                    \n",
    "                    data_arr = []\n",
    "                    for d in range(len(list(dataset))):\n",
    "                        data_arr.append(dataset[d])\n",
    "                    \n",
    "                    data_arr_2.append(data_arr)\n",
    "            \n",
    "                    if t_arr_bool == True:\n",
    "                        t_arr.append(data_arr[0])         \n",
    "                \n",
    "                master_arr.append(data_arr_2)\n",
    "                t_arr_bool = False\n",
    "                \n",
    "            \n",
    "            #df_start['radius'] = \n",
    "            \n",
    "            E = hdf.get('ELECTRODIFFUSION')\n",
    "            E_group_arr = list(E.keys())\n",
    "            ED_master_arr = []            \n",
    "            \n",
    "            ##### LOADING ELECTRODIFFUSION DATA\n",
    "            for x in range(len(E_group_arr)): # Looping through the electrodiffusion groups on the file\n",
    "                \n",
    "                E_group = E.get(E_group_arr[x])\n",
    "                \n",
    "                ED_data_arr =[] #stores the electrodiffusion data for a group\n",
    "                \n",
    "                for y in range(len(list(E_group.keys()))-1): # Looping through all the datasets of the group\n",
    "                    \n",
    "                    dataset = E_group.get(str(interval_arr[y+1]))\n",
    "                   \n",
    "                    ED_data_arr_2 = [] #stores the dataset values for one dataset\n",
    "                    for z in range(len(list(dataset))): # Looping through the individual datasets to extract data\n",
    "                        ED_data_arr_2.append(dataset[z])\n",
    "                    \n",
    "                    \n",
    "                    ED_data_arr.append(ED_data_arr_2) \n",
    "                    \n",
    "            \n",
    "                ED_master_arr.append(ED_data_arr) #contains all the electrodiffusion data for all the groups (1st index is the group, 2nd index is the interval)\n",
    "            \n",
    "            \n",
    "        ################\n",
    "        # DATAFRAMES\n",
    "        ################\n",
    "    \n",
    "        # START VALUE DATAFRAME\n",
    "        df_start_data = [master_arr[i][0][1:9] for i in range(len(comp_names_arr))]\n",
    "        df_start=pd.DataFrame(data=df_start_data, index=comp_names_arr)\n",
    "        df_start.columns = ['Radius', 'Length', 'Volume', 'Na_i', 'K_i', 'Cl_i','X_i','z_i']\n",
    "        \n",
    "        # END VALUE DATAFRAME\n",
    "        df_end_data = [master_arr[i][-1][1:9] for i in range(len(comp_names_arr))]\n",
    "        for i in range(len(comp_names_arr)):\n",
    "            df_end_data[i].append(master_arr[i][-1][-3]*1e3) #vm\n",
    "            df_end_data[i].append(master_arr[i][-1][-2]*1e3) #ek\n",
    "            df_end_data[i].append(master_arr[i][-1][-1]*1e3) #ecl\n",
    "            df_end_data[i].append((master_arr[i][-1][-3]-master_arr[i][-1][-1])*1e3) #driving force\n",
    "            \n",
    "        df_end=pd.DataFrame(data=df_end_data,index=comp_names_arr)\n",
    "        df_end.columns = ['Radius', 'Length', 'Volume', 'Na_i', 'K_i', 'Cl_i','X_i','z_i','Vm (mV)','Ek (mV)','ECl (mV)','Cl-Driving force (mV)']\n",
    "        \n",
    "        \n",
    "        # END TRANSMEMBRANE FLUX DATAFRAME\n",
    "        \n",
    "        final_mol_data =  [master_arr[i][-1][9:19]  for i in range(len(comp_names_arr))]\n",
    "        #semifinal_mol_data =  [master_arr[i][-2][9:19]  for i in range(len(comp_names_arr))]\n",
    "        \n",
    "        df_end_flux_data = []\n",
    "        \n",
    "    \n",
    "        for i in range(len(final_mol_data)):\n",
    "            temp_arr =[]\n",
    "            for j in range(len(final_mol_data[i])):\n",
    "                final_mol_data[i][j] = final_mol_data[i][j] * master_arr[i][-1][3]\n",
    "                #semifinal_mol_data[i][j] = semifinal_mol_data[i][j] * master_arr[i][-2][3]\n",
    "                #temp_arr.append(final_mol_data[i][j]-semifinal_mol_data[i][j])\n",
    "            #df_end_flux_data.append(temp_arr)\n",
    "            \n",
    "            \n",
    "        df_end_flux_cols = ['Na_net', 'Na_leak','Na_Atpase', 'K_net','K_leak','K_Atpase','K_kcc2', 'Cl_net','Cl_leak','Cl_kcc2']\n",
    "        df_end_flux = pd.DataFrame(data =final_mol_data, index = comp_names_arr, columns=df_end_flux_cols)\n",
    "        \n",
    "        # END ELECTRODIFFUSION DATAFRAME\n",
    "        df_end_ed_data = [ED_master_arr[i][-1][0:3] for i in range(len(ED_master_arr))]\n",
    "        for i in range(len(df_end_ed_data)):\n",
    "            for j in range(3):\n",
    "                df_end_ed_data[i][j] = df_end_ed_data[i][j] * master_arr[i][-1][3]\n",
    "                    \n",
    "        \n",
    "        df_end_ed_cols = ['Na_ED_flux', 'K_ED_flux', 'Cl_ED_flux']\n",
    "        df_end_ed = pd.DataFrame(data = df_end_ed_data, index = E_group_arr, columns=df_end_ed_cols)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # NET FLUX DATAFRAME\n",
    "        na_net_arr, k_net_arr,cl_net_arr,x_net_arr,total_net_arr = [],[],[],[],[]\n",
    "       \n",
    "        for i in range(len(comp_names_arr)):\n",
    "            na_net_arr.append(df_end_flux.iloc[i][0])\n",
    "            k_net_arr.append(df_end_flux.iloc[i][3])\n",
    "            cl_net_arr.append(df_end_flux.iloc[i][7])\n",
    "\n",
    "        x_net_arr = [((master_arr[i][-1][7] * master_arr[i][-1][3]) -(master_arr[i][-2][7] * master_arr[i][-2][3]))  for i in range(len(comp_names_arr))]\n",
    "        #(master_arr[i][-2][7]- master_arr[i][-2][3]\n",
    "        \n",
    "        for j in range(len(E_group_arr)):\n",
    "            na_net_arr[j] = na_net_arr[j] - df_end_ed.iloc[j][0]\n",
    "            na_net_arr[j+1] = na_net_arr[j+1] + df_end_ed.iloc[j][0]\n",
    "            k_net_arr[j] = k_net_arr[j] - df_end_ed.iloc[j][1]\n",
    "            k_net_arr[j+1] = k_net_arr[j+1] + df_end_ed.iloc[j][1]\n",
    "            cl_net_arr[j] = cl_net_arr[j] + df_end_ed.iloc[j][2]\n",
    "            cl_net_arr[j+1] = cl_net_arr[j+1] - df_end_ed.iloc[j][2]\n",
    "\n",
    "        total_net_arr = [na_net_arr[a]+k_net_arr[a]-cl_net_arr[a]-x_net_arr[a] for a in range(len(comp_names_arr))]\n",
    "\n",
    "\n",
    "        df_end_net_flux = pd.DataFrame(data ={'Na-Net':na_net_arr, 'K-Net':k_net_arr,'Cl-Net':cl_net_arr,'X-Net':x_net_arr,'Total':total_net_arr }, index=comp_names_arr)     \n",
    "\n",
    "\n",
    "            \n",
    "    except: \n",
    "        raise(\"File not found\")\n",
    "        raise(\"File needs to be in base directory\")\n",
    "\n",
    "\n",
    "btn_select.on_click(btn_select_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
